# LoRA for PointNet++ in Airborne LiDAR Semantic Segmentation

> Parameter‚Äëefficient fine‚Äëtuning (LoRA) for 3D point cloud semantic segmentation with PointNet++, evaluated on airborne LiDAR datasets.

[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](#license)
[![Python](https://img.shields.io/badge/python-3.9%2B-blue.svg)]()
[![PyTorch](https://img.shields.io/badge/PyTorch-1.12%2B-red.svg)]()

## üí° Overview
This repository contains code and assets accompanying the paper:
> **Efficient Task and Domain Adaptation in ALS Semantic Segmentation via LoRA for PointNet++**  
Semantic segmentation of airborne LiDAR point clouds enables a broad range of urban and environmental applications. However, domain shifts between training and operational data, as well as the frequent emergence of new semantic classes, pose significant challenges for deploying deep learning models effectively. In this work, we explore the integration of Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning technique, into the PointNet++ architecture to address these challenges. We evaluate LoRA in two realistic scenarios: domain adaptation and incremental learning with novel classes, using large-scale LiDAR datasets. Our experiments demonstrate that LoRA achieves superior performance compared to traditional full fine-tuning, showing greater resistance to catastrophic forgetting and improved generalization, particularly for underrepresented classes. Furthermore, LoRA maintains or exceeds baseline accuracy with substantially fewer trainable parameters, highlighting its suitability for resource-constrained deployment scenarios. We also present TerLiDAR, a publicly available annotated airborne LiDAR dataset, to support further research in domain adaptation for remote sensing.

> üìÑ **Paper link**: Will be released here as soon as the paper is published.


<p align="center">
  <img src="figs/PN++Lora.png" alt="Model teaser" width="100%">
</p>
<p align="left">
  <em>
PN++ architecture. Set Abstraction (SA) layers sample input points, group them, and apply PointNet to obtain high-dimensional representations. Feature Propagation (FP) layers upsample points and propagate features back to the original resolution.
 </em>
</p>

### LoRA applied to PointNet++
<p align="center">
  <img src="figs/diagramaLora.png" alt="Model teaser" width="50%">
</p>
<p align="left">
  <em>
    Orange boxes indicate trainable modules.  
    The input point cloud is represented as x ‚àà ‚Ñù<sup>N√óD</sup>, where N is the number of input points and D is the number of input features.  
    Each layer processes local neighborhoods, where N<sub>l</sub> is the number of sampled points at each level l, K is the number of neighboring points in the local region, and D<sub>in</sub> and D<sub>out</sub> are the input and output feature dimensions.  
    The output of the network is a per-point semantic prediction y ‚àà ‚Ñù<sup>N√óC</sup>, where C is the number of semantic classes.
  </em>
</p>

## ‚ú® Key Contributions
- **LoRA-enabled PointNet++**: Integration of Low-Rank Adaptation modules into the PointNet++ architecture to enable parameter-efficient fine-tuning.
- **Task & domain adaptation**: Evaluation across different airborne LiDAR datasets and in class extension scenarios, demonstrating LoRA's flexibility with minimal parameter overhead.
- **TerLiDAR dataset**: We release **TerLiDAR**, an open, annotated airborne LiDAR dataset covering 51.4 km¬≤ of mixed urban and forested landscapes along the Ter River in Catalonia, Spain.  


### TerLiDAR Dataset
We present TerLiDAR, a fully open and annotated airborne LiDAR dataset that covers 51.4~km\textsuperscript{2} of urban and forested areas along the Ter River in Catalonia, Spain. The data were acquired in July 2021 using an ALS system mounted on a georeferenced aircraft operated by ICGC. The dataset comprises 692 million colorized 3D points, each annotated with one of the semantic classes listed in the paper.

<p align="center">
  <img src="figs/overview.PNG" alt="TerLiDAR coverage area" width="100%">
</p>
<p align="center">
  <em>
    Geographic coverage of the TerLiDAR dataset along the Ter River in Catalonia, Spain.  
  </em>
</p>

The classes are described as follows:
1. **Default** ‚Äì Points that could not be classified during the classification process.  
2. **Ground** ‚Äì Points belonging to the terrain.  
3. **Low vegetation** ‚Äì Points corresponding to low vegetation such as shrubs, crops, and the lower parts of trees (0.3 m < height ‚â§ 2.0 m).  
4. **Medium vegetation** ‚Äì Points belonging to medium vegetation, which may include taller shrubs, crops, and parts of tree canopies (2.0 m < height ‚â§ 3.0 m).  
5. **High vegetation** ‚Äì Points corresponding to high vegetation, primarily points within tree canopies (height > 3.0 m).  
6. **Buildings** ‚Äì Points generally classified on building rooftops.  
7. **Low Points** ‚Äì Points with negative height relative to the ground, usually sensor noise.  
8. **Ground key points** ‚Äì Simplified points previously classified as ground (Class 2), used for constructing the Digital Terrain Model.  
9. **Air points** ‚Äì Points detected above the terrain, often spurious returns.  
10. **Other ground points** ‚Äì Points near the ground, such as those pertaining to grass, that could not be classified as ground.  
11. **Power lines** ‚Äì Points representing electric power lines.  
12. **Transmission tower** ‚Äì Points on electrical towers.  
13. **Walls** ‚Äì Points belonging mostly to building fa√ßades.  
14. **Above buildings** ‚Äì Points located above buildings, such as chimneys, solar panels, or awnings.  
15. **Other towers** ‚Äì Points corresponding to towers not classified as electric towers (e.g., wind turbines, observation towers).  
16. **Noise** ‚Äì Points identified as noise produced by the sensor.  


<p align="center">
  <img src="figs/RGB.png" alt="TerLiDAR example point clouds" width="100%">
  <img src="figs/classification_legend.PNG" alt="TerLiDAR example point clouds" width="100%">
</p>
<p align="center">
  <em>
    Visualization of a LAS tile using RGB values and corresponding semantic classes.
  </em>
</p>


## üì¶ Environment
- Python 3.9+
- PyTorch 1.12+ with CUDA 11.x (recommended)

Quick setup:
```bash
conda create -n lora-pn2 python=3.10 -y
conda activate lora-pn2
pip install -r requirements.txt
